---
title: "Textming"
author: "Siwei Hu"
date: "November 4, 2018"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tm.plugin.webmining)
library(RDCOMClient)
library(tidytext)
library(tidyverse)
```


```{r,echo=FALSE,warning=FALSE}
library(rvest)

url <- "https://correlaid.org/blog/posts/data-science-books-to-read"

txt <- read_html(url) %>% html_nodes(".post-content h3 , .post-content p , .subheading , h2") %>% html_text()

## import text as data frame
txt <- as.data.frame(txt,stringsAsFactors = FALSE)
#give column name "text"
colnames(txt) <- "text"




```





```{r,echo=FALSE,warning=FALSE}
library(stringr)

# Change each paragraph to one-token-per-document-per-row 
txt.sep <- txt %>% 
#sign linenumber  
  mutate(linenumber = row_number())%>% 
  unnest_tokens(word,text) %>% 
  anti_join(stop_words) %>% 
  filter(str_detect(word,"[:alpha:]"))

  
#count the amount of each word  
txt.sep.n <- txt.sep %>%  count(word,sort = TRUE) %>% 
  mutate(name = "recommondation")
```

```{r,echo=FALSE,warning=FALSE}
# analysis the sentiment in each sentence/ or several sentence(because i seperte sentences by ".")
txt.sep.afin <- txt.sep %>% 
  inner_join(get_sentiments("afinn")) %>% 
  mutate(method = "AFINN")

txt.afin <- txt.sep %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(linenumber) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

# sentiment with nrc 
txt.sep.nrc <-   txt.sep %>% 
  inner_join(get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive","negative"))) %>%
  mutate(method = "nrc")
#sentiment with bing
txt.sep.bing <- txt.sep%>% inner_join(get_sentiments("bing")) %>% 
  mutate(method = "bing")

# combine nrc and bing, then analyze the sentiment in different linenumber
txt.bing.nrc <- bind_rows(txt.sep.nrc,txt.sep.bing) %>% 
  count(method, linenumber, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  select(method,linenumber,sentiment)
#combine all three different ways
txt.sentiment <-bind_rows(txt.afin, txt.bing.nrc)
# use ggplot to compare the sentiment from three different methods in the same line. 
ggplot(aes(linenumber, sentiment, fill = method),data = txt.sentiment) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```


```{r,echo=FALSE,warning=FALSE}
# do inner_join with bing, and count how many word has postive and negetive
bing_word_counts <- txt.sep %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
# do postive words chart and negative words chart
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>% 
  mutate(word = reorder(word, n))%>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```

```{r,echo=FALSE,warning=FALSE}
#do a wordcloud
library(wordcloud)
library(reshape2)
txt.sep %>%
  anti_join(stop_words) %>%
  count(word,sort = TRUE) %>% 
 with(wordcloud(word, n, max.words = 100))
#do classier wordcloud(positive and negative)
txt.sep.bing %>% 
  count(word,sentiment,sort = TRUE) %>% 
   acast(word~sentiment,fill=0) %>% 
  comparison.cloud(color = c("#F8766D","#00BFC4"),max.words = 60)
```


```{r,echo=FALSE,warning=FALSE}
## import the text document from URL
url1 <- "https://correlaid.org/blog/posts/reconstructing-cambridge-analytica"

txt_fb <- read_html(url1) %>% html_nodes("h4 , #blog li , .post-content h3 , .post-content p , p a , .subheading , h2") %>% html_text()

## import text as data frame
txt_fb <- as.data.frame(txt_fb,stringsAsFactors = FALSE)
#give column name "text"
colnames(txt_fb) <- "text"
```

```{r,echo=FALSE,warning=FALSE}

# Change each sentence to one-token-per-document-per-row 
txt_fb_sep <- txt_fb%>% 
#sign linenumber  
  mutate(linenumber = row_number()) %>% 
  unnest_tokens(word,text) %>% 
  anti_join(stop_words) %>% 
#filter useless number
    filter(str_detect(word,"[:alpha:]"))

txt_fb_n <- txt_fb_sep %>% count(word, sort = TRUE) %>% 
  mutate(name = "neurotic machine")

```
```{r,warning=FALSE,echo=FALSE}
txt_fb_afin <- txt_fb_sep %>% 
  inner_join(get_sentiments("afinn")) %>% 
  mutate(method = "AFINN")

txt_afin <- txt_fb_sep %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber%/%5) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

# sentiment with nrc 
txt_fb_nrc <- txt_fb_sep %>% 
  inner_join(get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive","negative"))) %>%
  mutate(method = "nrc")
#sentiment with bing
txt_fb_bing <- txt_fb_sep%>% inner_join(get_sentiments("bing")) %>% 
  mutate(method = "bing")

# combine nrc and bing, then analyze the sentiment in different linenumber
txt_bing_nrc <- bind_rows(txt_fb_nrc,txt_fb_bing) %>% 
  count(method,index = linenumber%/%5, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  select(method,index,sentiment)
#combine all three different ways
txt_sentiment <-bind_rows(txt_afin, txt_bing_nrc)
# use ggplot to compare the sentiment from three different methods in the same line_ 
ggplot(aes(index, sentiment, fill = method),data = txt_sentiment) +
  geom_col(show_legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

```{r,echo=FALSE,warning=FALSE}
# do inner_join with bing, and count how many word has postive and negetive
fb_bing_word_counts <- txt_fb_sep %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
# do postive words chart and negative words chart
fb_bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(4) %>%
  ungroup() %>% 
  mutate(word = reorder(word, n))%>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()


```

```{r,echo=FALSE,warning=FALSE}
library(reshape2)
txt_fb_sep %>%
  anti_join(stop_words) %>%
  count(word,sort = TRUE) %>% 
 with(wordcloud(word, n))

fb_bing_word_counts%>% 
  reshape2::acast(word ~ sentiment,value.var = 'n',fill=0,) %>% 
  comparison.cloud(colors = c("#F8766D","#00BFC4"))

```

```{r,echo=FALSE,warning=FALSE}
#combine two article count data into one df
#calculate the ti_idf to understand the importance of word to this article
tf.idf <- bind_rows(txt.sep.n,txt_fb_n) 
tf.idf <- tf.idf %>% 
  bind_tf_idf(word,name,n) %>% 
  arrange(desc(tf_idf)) %>%  
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(name) %>% 
  top_n(10) %>% 
  ungroup 
#draw the chart to show its importance
  ggplot(data = tf.idf,aes(word, tf_idf, fill = name)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~name, ncol = 2, scales = "free") +
  coord_flip()

```